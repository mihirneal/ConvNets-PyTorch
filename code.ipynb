{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Device Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Transform\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Hyperparameters\n",
    "input_size = 784\n",
    "hidden_class = 1000\n",
    "num_classes = 10\n",
    "num_epoch = 50\n",
    "learning_rate = 0.001\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Importing data and Preprocessing it\n",
    "train_dataset = datasets.CIFAR10(root = './data', train=True, transform= transform, download=True)\n",
    "test_dataset = datasets.CIFAR10(root = './data', train=False, transform= transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Mode\n",
    "model = ConvolutionalNeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criterion and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1 / 50], Step: [1000 / 5000], Loss: 2.2680\n",
      "Epoch: [1 / 50], Step: [2000 / 5000], Loss: 2.3139\n",
      "Epoch: [1 / 50], Step: [3000 / 5000], Loss: 2.3083\n",
      "Epoch: [1 / 50], Step: [4000 / 5000], Loss: 2.2858\n",
      "Epoch: [1 / 50], Step: [5000 / 5000], Loss: 2.3011\n",
      "Epoch: [2 / 50], Step: [1000 / 5000], Loss: 2.2879\n",
      "Epoch: [2 / 50], Step: [2000 / 5000], Loss: 2.2824\n",
      "Epoch: [2 / 50], Step: [3000 / 5000], Loss: 2.3012\n",
      "Epoch: [2 / 50], Step: [4000 / 5000], Loss: 2.3610\n",
      "Epoch: [2 / 50], Step: [5000 / 5000], Loss: 2.1306\n",
      "Epoch: [3 / 50], Step: [1000 / 5000], Loss: 2.1994\n",
      "Epoch: [3 / 50], Step: [2000 / 5000], Loss: 2.0324\n",
      "Epoch: [3 / 50], Step: [3000 / 5000], Loss: 1.9771\n",
      "Epoch: [3 / 50], Step: [4000 / 5000], Loss: 2.3008\n",
      "Epoch: [3 / 50], Step: [5000 / 5000], Loss: 1.8430\n",
      "Epoch: [4 / 50], Step: [1000 / 5000], Loss: 2.4965\n",
      "Epoch: [4 / 50], Step: [2000 / 5000], Loss: 1.7553\n",
      "Epoch: [4 / 50], Step: [3000 / 5000], Loss: 1.7694\n",
      "Epoch: [4 / 50], Step: [4000 / 5000], Loss: 1.8228\n",
      "Epoch: [4 / 50], Step: [5000 / 5000], Loss: 1.7402\n",
      "Epoch: [5 / 50], Step: [1000 / 5000], Loss: 2.1301\n",
      "Epoch: [5 / 50], Step: [2000 / 5000], Loss: 1.8704\n",
      "Epoch: [5 / 50], Step: [3000 / 5000], Loss: 1.5972\n",
      "Epoch: [5 / 50], Step: [4000 / 5000], Loss: 2.0033\n",
      "Epoch: [5 / 50], Step: [5000 / 5000], Loss: 1.0935\n",
      "Epoch: [6 / 50], Step: [1000 / 5000], Loss: 2.2030\n",
      "Epoch: [6 / 50], Step: [2000 / 5000], Loss: 1.7992\n",
      "Epoch: [6 / 50], Step: [3000 / 5000], Loss: 1.3957\n",
      "Epoch: [6 / 50], Step: [4000 / 5000], Loss: 1.9098\n",
      "Epoch: [6 / 50], Step: [5000 / 5000], Loss: 1.9773\n",
      "Epoch: [7 / 50], Step: [1000 / 5000], Loss: 1.9008\n",
      "Epoch: [7 / 50], Step: [2000 / 5000], Loss: 1.5476\n",
      "Epoch: [7 / 50], Step: [3000 / 5000], Loss: 2.0392\n",
      "Epoch: [7 / 50], Step: [4000 / 5000], Loss: 1.6075\n",
      "Epoch: [7 / 50], Step: [5000 / 5000], Loss: 2.0737\n",
      "Epoch: [8 / 50], Step: [1000 / 5000], Loss: 2.0492\n",
      "Epoch: [8 / 50], Step: [2000 / 5000], Loss: 1.2009\n",
      "Epoch: [8 / 50], Step: [3000 / 5000], Loss: 1.8706\n",
      "Epoch: [8 / 50], Step: [4000 / 5000], Loss: 1.7447\n",
      "Epoch: [8 / 50], Step: [5000 / 5000], Loss: 1.1958\n",
      "Epoch: [9 / 50], Step: [1000 / 5000], Loss: 1.5943\n",
      "Epoch: [9 / 50], Step: [2000 / 5000], Loss: 0.9622\n",
      "Epoch: [9 / 50], Step: [3000 / 5000], Loss: 1.6675\n",
      "Epoch: [9 / 50], Step: [4000 / 5000], Loss: 1.8982\n",
      "Epoch: [9 / 50], Step: [5000 / 5000], Loss: 1.4138\n",
      "Epoch: [10 / 50], Step: [1000 / 5000], Loss: 1.4823\n",
      "Epoch: [10 / 50], Step: [2000 / 5000], Loss: 1.1325\n",
      "Epoch: [10 / 50], Step: [3000 / 5000], Loss: 1.8999\n",
      "Epoch: [10 / 50], Step: [4000 / 5000], Loss: 1.5685\n",
      "Epoch: [10 / 50], Step: [5000 / 5000], Loss: 1.2334\n",
      "Epoch: [11 / 50], Step: [1000 / 5000], Loss: 1.2603\n",
      "Epoch: [11 / 50], Step: [2000 / 5000], Loss: 1.0902\n",
      "Epoch: [11 / 50], Step: [3000 / 5000], Loss: 1.2441\n",
      "Epoch: [11 / 50], Step: [4000 / 5000], Loss: 1.1402\n",
      "Epoch: [11 / 50], Step: [5000 / 5000], Loss: 1.6533\n",
      "Epoch: [12 / 50], Step: [1000 / 5000], Loss: 1.3828\n",
      "Epoch: [12 / 50], Step: [2000 / 5000], Loss: 1.6862\n",
      "Epoch: [12 / 50], Step: [3000 / 5000], Loss: 1.1340\n",
      "Epoch: [12 / 50], Step: [4000 / 5000], Loss: 1.4680\n",
      "Epoch: [12 / 50], Step: [5000 / 5000], Loss: 1.0301\n",
      "Epoch: [13 / 50], Step: [1000 / 5000], Loss: 1.5625\n",
      "Epoch: [13 / 50], Step: [2000 / 5000], Loss: 1.3249\n",
      "Epoch: [13 / 50], Step: [3000 / 5000], Loss: 1.2777\n",
      "Epoch: [13 / 50], Step: [4000 / 5000], Loss: 1.5914\n",
      "Epoch: [13 / 50], Step: [5000 / 5000], Loss: 1.2899\n",
      "Epoch: [14 / 50], Step: [1000 / 5000], Loss: 1.5362\n",
      "Epoch: [14 / 50], Step: [2000 / 5000], Loss: 0.7775\n",
      "Epoch: [14 / 50], Step: [3000 / 5000], Loss: 0.9125\n",
      "Epoch: [14 / 50], Step: [4000 / 5000], Loss: 1.2715\n",
      "Epoch: [14 / 50], Step: [5000 / 5000], Loss: 1.2060\n",
      "Epoch: [15 / 50], Step: [1000 / 5000], Loss: 0.8917\n",
      "Epoch: [15 / 50], Step: [2000 / 5000], Loss: 1.4324\n",
      "Epoch: [15 / 50], Step: [3000 / 5000], Loss: 0.9854\n",
      "Epoch: [15 / 50], Step: [4000 / 5000], Loss: 1.2086\n",
      "Epoch: [15 / 50], Step: [5000 / 5000], Loss: 1.1063\n",
      "Epoch: [16 / 50], Step: [1000 / 5000], Loss: 1.3855\n",
      "Epoch: [16 / 50], Step: [2000 / 5000], Loss: 1.1573\n",
      "Epoch: [16 / 50], Step: [3000 / 5000], Loss: 1.2780\n",
      "Epoch: [16 / 50], Step: [4000 / 5000], Loss: 1.2359\n",
      "Epoch: [16 / 50], Step: [5000 / 5000], Loss: 1.1715\n",
      "Epoch: [17 / 50], Step: [1000 / 5000], Loss: 1.4497\n",
      "Epoch: [17 / 50], Step: [2000 / 5000], Loss: 1.4545\n",
      "Epoch: [17 / 50], Step: [3000 / 5000], Loss: 0.6494\n",
      "Epoch: [17 / 50], Step: [4000 / 5000], Loss: 0.3518\n",
      "Epoch: [17 / 50], Step: [5000 / 5000], Loss: 1.3018\n",
      "Epoch: [18 / 50], Step: [1000 / 5000], Loss: 1.0257\n",
      "Epoch: [18 / 50], Step: [2000 / 5000], Loss: 0.9414\n",
      "Epoch: [18 / 50], Step: [3000 / 5000], Loss: 1.0102\n",
      "Epoch: [18 / 50], Step: [4000 / 5000], Loss: 1.4231\n",
      "Epoch: [18 / 50], Step: [5000 / 5000], Loss: 1.6280\n",
      "Epoch: [19 / 50], Step: [1000 / 5000], Loss: 1.3363\n",
      "Epoch: [19 / 50], Step: [2000 / 5000], Loss: 1.4466\n",
      "Epoch: [19 / 50], Step: [3000 / 5000], Loss: 1.5794\n",
      "Epoch: [19 / 50], Step: [4000 / 5000], Loss: 1.0820\n",
      "Epoch: [19 / 50], Step: [5000 / 5000], Loss: 0.8533\n",
      "Epoch: [20 / 50], Step: [1000 / 5000], Loss: 1.6089\n",
      "Epoch: [20 / 50], Step: [2000 / 5000], Loss: 1.5818\n",
      "Epoch: [20 / 50], Step: [3000 / 5000], Loss: 1.6838\n",
      "Epoch: [20 / 50], Step: [4000 / 5000], Loss: 1.3586\n",
      "Epoch: [20 / 50], Step: [5000 / 5000], Loss: 1.3141\n",
      "Epoch: [21 / 50], Step: [1000 / 5000], Loss: 1.3383\n",
      "Epoch: [21 / 50], Step: [2000 / 5000], Loss: 1.0253\n",
      "Epoch: [21 / 50], Step: [3000 / 5000], Loss: 0.7340\n",
      "Epoch: [21 / 50], Step: [4000 / 5000], Loss: 0.9181\n",
      "Epoch: [21 / 50], Step: [5000 / 5000], Loss: 1.2421\n",
      "Epoch: [22 / 50], Step: [1000 / 5000], Loss: 1.0117\n",
      "Epoch: [22 / 50], Step: [2000 / 5000], Loss: 1.0519\n",
      "Epoch: [22 / 50], Step: [3000 / 5000], Loss: 0.9959\n",
      "Epoch: [22 / 50], Step: [4000 / 5000], Loss: 1.1208\n",
      "Epoch: [22 / 50], Step: [5000 / 5000], Loss: 0.8524\n",
      "Epoch: [23 / 50], Step: [1000 / 5000], Loss: 1.2032\n",
      "Epoch: [23 / 50], Step: [2000 / 5000], Loss: 1.5078\n",
      "Epoch: [23 / 50], Step: [3000 / 5000], Loss: 1.1523\n",
      "Epoch: [23 / 50], Step: [4000 / 5000], Loss: 1.1705\n",
      "Epoch: [23 / 50], Step: [5000 / 5000], Loss: 0.6602\n",
      "Epoch: [24 / 50], Step: [1000 / 5000], Loss: 0.7867\n",
      "Epoch: [24 / 50], Step: [2000 / 5000], Loss: 0.9871\n",
      "Epoch: [24 / 50], Step: [3000 / 5000], Loss: 0.9354\n",
      "Epoch: [24 / 50], Step: [4000 / 5000], Loss: 1.0247\n",
      "Epoch: [24 / 50], Step: [5000 / 5000], Loss: 1.2958\n",
      "Epoch: [25 / 50], Step: [1000 / 5000], Loss: 1.4890\n",
      "Epoch: [25 / 50], Step: [2000 / 5000], Loss: 1.8347\n",
      "Epoch: [25 / 50], Step: [3000 / 5000], Loss: 1.6029\n",
      "Epoch: [25 / 50], Step: [4000 / 5000], Loss: 0.7159\n",
      "Epoch: [25 / 50], Step: [5000 / 5000], Loss: 1.3065\n",
      "Epoch: [26 / 50], Step: [1000 / 5000], Loss: 0.8066\n",
      "Epoch: [26 / 50], Step: [2000 / 5000], Loss: 0.7834\n",
      "Epoch: [26 / 50], Step: [3000 / 5000], Loss: 0.6399\n",
      "Epoch: [26 / 50], Step: [4000 / 5000], Loss: 1.0996\n",
      "Epoch: [26 / 50], Step: [5000 / 5000], Loss: 1.3297\n",
      "Epoch: [27 / 50], Step: [1000 / 5000], Loss: 0.9755\n",
      "Epoch: [27 / 50], Step: [2000 / 5000], Loss: 0.5944\n",
      "Epoch: [27 / 50], Step: [3000 / 5000], Loss: 1.0034\n",
      "Epoch: [27 / 50], Step: [4000 / 5000], Loss: 0.9823\n",
      "Epoch: [27 / 50], Step: [5000 / 5000], Loss: 1.0675\n",
      "Epoch: [28 / 50], Step: [1000 / 5000], Loss: 0.9407\n",
      "Epoch: [28 / 50], Step: [2000 / 5000], Loss: 0.5051\n",
      "Epoch: [28 / 50], Step: [3000 / 5000], Loss: 0.6280\n",
      "Epoch: [28 / 50], Step: [4000 / 5000], Loss: 1.0530\n",
      "Epoch: [28 / 50], Step: [5000 / 5000], Loss: 0.8892\n",
      "Epoch: [29 / 50], Step: [1000 / 5000], Loss: 0.6118\n",
      "Epoch: [29 / 50], Step: [2000 / 5000], Loss: 1.6893\n",
      "Epoch: [29 / 50], Step: [3000 / 5000], Loss: 0.9921\n",
      "Epoch: [29 / 50], Step: [4000 / 5000], Loss: 1.0431\n",
      "Epoch: [29 / 50], Step: [5000 / 5000], Loss: 0.8661\n",
      "Epoch: [30 / 50], Step: [1000 / 5000], Loss: 1.2809\n",
      "Epoch: [30 / 50], Step: [2000 / 5000], Loss: 1.1845\n",
      "Epoch: [30 / 50], Step: [3000 / 5000], Loss: 1.3131\n",
      "Epoch: [30 / 50], Step: [4000 / 5000], Loss: 1.8835\n",
      "Epoch: [30 / 50], Step: [5000 / 5000], Loss: 1.3993\n",
      "Epoch: [31 / 50], Step: [1000 / 5000], Loss: 0.7764\n",
      "Epoch: [31 / 50], Step: [2000 / 5000], Loss: 1.0701\n",
      "Epoch: [31 / 50], Step: [3000 / 5000], Loss: 0.7249\n",
      "Epoch: [31 / 50], Step: [4000 / 5000], Loss: 1.2647\n",
      "Epoch: [31 / 50], Step: [5000 / 5000], Loss: 1.3882\n",
      "Epoch: [32 / 50], Step: [1000 / 5000], Loss: 1.3176\n",
      "Epoch: [32 / 50], Step: [2000 / 5000], Loss: 0.6869\n",
      "Epoch: [32 / 50], Step: [3000 / 5000], Loss: 0.6297\n",
      "Epoch: [32 / 50], Step: [4000 / 5000], Loss: 1.3681\n",
      "Epoch: [32 / 50], Step: [5000 / 5000], Loss: 1.2383\n",
      "Epoch: [33 / 50], Step: [1000 / 5000], Loss: 1.2737\n",
      "Epoch: [33 / 50], Step: [2000 / 5000], Loss: 1.1418\n",
      "Epoch: [33 / 50], Step: [3000 / 5000], Loss: 0.4422\n",
      "Epoch: [33 / 50], Step: [4000 / 5000], Loss: 1.0071\n",
      "Epoch: [33 / 50], Step: [5000 / 5000], Loss: 1.7215\n",
      "Epoch: [34 / 50], Step: [1000 / 5000], Loss: 0.9888\n",
      "Epoch: [34 / 50], Step: [2000 / 5000], Loss: 0.7182\n",
      "Epoch: [34 / 50], Step: [3000 / 5000], Loss: 0.8879\n",
      "Epoch: [34 / 50], Step: [4000 / 5000], Loss: 1.0085\n",
      "Epoch: [34 / 50], Step: [5000 / 5000], Loss: 0.8041\n",
      "Epoch: [35 / 50], Step: [1000 / 5000], Loss: 0.4051\n",
      "Epoch: [35 / 50], Step: [2000 / 5000], Loss: 1.3873\n",
      "Epoch: [35 / 50], Step: [3000 / 5000], Loss: 0.7098\n",
      "Epoch: [35 / 50], Step: [4000 / 5000], Loss: 1.3989\n",
      "Epoch: [35 / 50], Step: [5000 / 5000], Loss: 1.3127\n",
      "Epoch: [36 / 50], Step: [1000 / 5000], Loss: 0.5710\n",
      "Epoch: [36 / 50], Step: [2000 / 5000], Loss: 0.6982\n",
      "Epoch: [36 / 50], Step: [3000 / 5000], Loss: 0.5889\n",
      "Epoch: [36 / 50], Step: [4000 / 5000], Loss: 0.7950\n",
      "Epoch: [36 / 50], Step: [5000 / 5000], Loss: 1.1627\n",
      "Epoch: [37 / 50], Step: [1000 / 5000], Loss: 1.2593\n",
      "Epoch: [37 / 50], Step: [2000 / 5000], Loss: 1.4161\n",
      "Epoch: [37 / 50], Step: [3000 / 5000], Loss: 0.7186\n",
      "Epoch: [37 / 50], Step: [4000 / 5000], Loss: 0.8364\n",
      "Epoch: [37 / 50], Step: [5000 / 5000], Loss: 1.1739\n",
      "Epoch: [38 / 50], Step: [1000 / 5000], Loss: 1.3083\n",
      "Epoch: [38 / 50], Step: [2000 / 5000], Loss: 1.0103\n",
      "Epoch: [38 / 50], Step: [3000 / 5000], Loss: 1.6014\n",
      "Epoch: [38 / 50], Step: [4000 / 5000], Loss: 0.7427\n",
      "Epoch: [38 / 50], Step: [5000 / 5000], Loss: 0.4006\n",
      "Epoch: [39 / 50], Step: [1000 / 5000], Loss: 0.3399\n",
      "Epoch: [39 / 50], Step: [2000 / 5000], Loss: 0.9437\n",
      "Epoch: [39 / 50], Step: [3000 / 5000], Loss: 0.9034\n",
      "Epoch: [39 / 50], Step: [4000 / 5000], Loss: 1.0342\n",
      "Epoch: [39 / 50], Step: [5000 / 5000], Loss: 1.2453\n",
      "Epoch: [40 / 50], Step: [1000 / 5000], Loss: 0.6020\n",
      "Epoch: [40 / 50], Step: [2000 / 5000], Loss: 0.7949\n",
      "Epoch: [40 / 50], Step: [3000 / 5000], Loss: 0.8800\n",
      "Epoch: [40 / 50], Step: [4000 / 5000], Loss: 1.0699\n",
      "Epoch: [40 / 50], Step: [5000 / 5000], Loss: 0.6938\n",
      "Epoch: [41 / 50], Step: [1000 / 5000], Loss: 0.4987\n",
      "Epoch: [41 / 50], Step: [2000 / 5000], Loss: 0.7590\n",
      "Epoch: [41 / 50], Step: [3000 / 5000], Loss: 0.6924\n",
      "Epoch: [41 / 50], Step: [4000 / 5000], Loss: 0.9511\n",
      "Epoch: [41 / 50], Step: [5000 / 5000], Loss: 0.3900\n",
      "Epoch: [42 / 50], Step: [1000 / 5000], Loss: 1.0885\n",
      "Epoch: [42 / 50], Step: [2000 / 5000], Loss: 0.9174\n",
      "Epoch: [42 / 50], Step: [3000 / 5000], Loss: 0.9372\n",
      "Epoch: [42 / 50], Step: [4000 / 5000], Loss: 0.8241\n",
      "Epoch: [42 / 50], Step: [5000 / 5000], Loss: 0.6864\n",
      "Epoch: [43 / 50], Step: [1000 / 5000], Loss: 0.4389\n",
      "Epoch: [43 / 50], Step: [2000 / 5000], Loss: 1.6648\n",
      "Epoch: [43 / 50], Step: [3000 / 5000], Loss: 1.3787\n",
      "Epoch: [43 / 50], Step: [4000 / 5000], Loss: 0.5841\n",
      "Epoch: [43 / 50], Step: [5000 / 5000], Loss: 1.3415\n",
      "Epoch: [44 / 50], Step: [1000 / 5000], Loss: 1.0879\n",
      "Epoch: [44 / 50], Step: [2000 / 5000], Loss: 0.7338\n",
      "Epoch: [44 / 50], Step: [3000 / 5000], Loss: 0.8698\n",
      "Epoch: [44 / 50], Step: [4000 / 5000], Loss: 0.7111\n",
      "Epoch: [44 / 50], Step: [5000 / 5000], Loss: 0.8242\n",
      "Epoch: [45 / 50], Step: [1000 / 5000], Loss: 1.2716\n",
      "Epoch: [45 / 50], Step: [2000 / 5000], Loss: 0.4410\n",
      "Epoch: [45 / 50], Step: [3000 / 5000], Loss: 1.1157\n",
      "Epoch: [45 / 50], Step: [4000 / 5000], Loss: 1.3142\n",
      "Epoch: [45 / 50], Step: [5000 / 5000], Loss: 0.5116\n",
      "Epoch: [46 / 50], Step: [1000 / 5000], Loss: 0.4669\n",
      "Epoch: [46 / 50], Step: [2000 / 5000], Loss: 0.5832\n",
      "Epoch: [46 / 50], Step: [3000 / 5000], Loss: 1.1555\n",
      "Epoch: [46 / 50], Step: [4000 / 5000], Loss: 1.0453\n",
      "Epoch: [46 / 50], Step: [5000 / 5000], Loss: 1.0756\n",
      "Epoch: [47 / 50], Step: [1000 / 5000], Loss: 0.9714\n",
      "Epoch: [47 / 50], Step: [2000 / 5000], Loss: 0.7518\n",
      "Epoch: [47 / 50], Step: [3000 / 5000], Loss: 0.6391\n",
      "Epoch: [47 / 50], Step: [4000 / 5000], Loss: 1.2014\n",
      "Epoch: [47 / 50], Step: [5000 / 5000], Loss: 0.6498\n",
      "Epoch: [48 / 50], Step: [1000 / 5000], Loss: 1.0897\n",
      "Epoch: [48 / 50], Step: [2000 / 5000], Loss: 0.9353\n",
      "Epoch: [48 / 50], Step: [3000 / 5000], Loss: 0.5936\n",
      "Epoch: [48 / 50], Step: [4000 / 5000], Loss: 1.2254\n",
      "Epoch: [48 / 50], Step: [5000 / 5000], Loss: 0.6753\n",
      "Epoch: [49 / 50], Step: [1000 / 5000], Loss: 0.8829\n",
      "Epoch: [49 / 50], Step: [2000 / 5000], Loss: 0.9496\n",
      "Epoch: [49 / 50], Step: [3000 / 5000], Loss: 1.5744\n",
      "Epoch: [49 / 50], Step: [4000 / 5000], Loss: 0.4739\n",
      "Epoch: [49 / 50], Step: [5000 / 5000], Loss: 0.9990\n",
      "Epoch: [50 / 50], Step: [1000 / 5000], Loss: 0.7569\n",
      "Epoch: [50 / 50], Step: [2000 / 5000], Loss: 0.4918\n",
      "Epoch: [50 / 50], Step: [3000 / 5000], Loss: 0.4638\n",
      "Epoch: [50 / 50], Step: [4000 / 5000], Loss: 0.9797\n",
      "Epoch: [50 / 50], Step: [5000 / 5000], Loss: 1.4328\n"
     ]
    }
   ],
   "source": [
    "#Training the Model\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for ep in range(num_epoch):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #Forward Pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #Backward Pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Printing output\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f'Epoch: [{ep + 1} / {num_epoch}], Step: [{i + 1} / {n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 63.03 %\n",
      "Accuracy of plane : 62.9 %\n",
      "Accuracy of car : 70.7 %\n",
      "Accuracy of bird : 54.6 %\n",
      "Accuracy of cat : 40.5 %\n",
      "Accuracy of deer : 61.4 %\n",
      "Accuracy of dog : 38.2 %\n",
      "Accuracy of frog : 71.7 %\n",
      "Accuracy of horse : 82.0 %\n",
      "Accuracy of ship : 77.0 %\n",
      "Accuracy of truck : 71.3 %\n"
     ]
    }
   ],
   "source": [
    "#Checking Accuracy\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        samples += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "    \n",
    "    acc = 100 * correct / samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]} : {acc} %')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf27035b7dc97182e329f4f3264e74024bcb2370fef5d6f059b9761c10d841e0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
